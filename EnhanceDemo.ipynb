{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import utils as vutils\n",
    "from Net import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadImage(data.Dataset):\n",
    "    def __init__(self, image_list):\n",
    "        self.image_list = image_list\n",
    "        self.data_list = {\"img_in\": []}\n",
    "        for num_img in range(len(image_list)):\n",
    "            self.data_list[\"img_in\"].append(image_list[num_img])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_in_path = self.data_list[\"img_in\"][index]\n",
    "        img_in = Image.open(img_in_path).convert(\"RGB\")\n",
    "        img_in = img_in.resize((512, 512))\n",
    "        t_list = [transforms.ToTensor()]\n",
    "        composed_transform = transforms.Compose(t_list)\n",
    "        img_in = composed_transform(img_in)\n",
    "        inputs = {\"img_in\": img_in}\n",
    "        return inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list[\"img_in\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_pil(image_tensor):\n",
    "    image_tensor = image_tensor.detach().cpu()\n",
    "    image_tensor = image_tensor[0, :, :, :]\n",
    "    grid = vutils.make_grid(image_tensor)\n",
    "    # Add 0.5 after unnormalizing to [0, 255] to round to nearest integer\n",
    "    ndarr = grid.mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to(\"cpu\", torch.uint8).numpy()\n",
    "    return Image.fromarray(ndarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(out_path, img_name, results, key):\n",
    "    func_time = time.time()\n",
    "    img_path = os.path.join(out_path,f\"{key}_{img_name}\")\n",
    "    res_list = results[key]\n",
    "    pil_preds = []\n",
    "\n",
    "    if res_list:\n",
    "        # Stack Images\n",
    "        start_time = time.time()\n",
    "        for img_tensor in res_list:\n",
    "            pil_img = tensor_to_pil(img_tensor)\n",
    "            pil_preds.append(pil_img)\n",
    "        imgs_comb = np.vstack(pil_preds)\n",
    "        print(\"Stack: \", time.time() - start_time)\n",
    "\n",
    "        # Write image\n",
    "        start_time = time.time()\n",
    "        cv2.imwrite(img_path,imgs_comb)\n",
    "        print(\"Write: \", time.time() - start_time)\n",
    "        print(\"Func: \", time.time() - func_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, tqdm_bar):\n",
    "    predictions = []\n",
    "    sums = []\n",
    "    for batch_idx, input in enumerate(tqdm_bar):\n",
    "        model.train()\n",
    "\n",
    "        img_in = Variable(torch.FloatTensor(input[\"img_in\"])).cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        net_tensor = model(img_in)\n",
    "        sum_tensor = img_in + net_tensor\n",
    "\n",
    "        if (batch_idx+1) % 10 == 0:\n",
    "            predictions.append(net_tensor)\n",
    "            sums.append(sum_tensor)\n",
    "        tqdm_bar.update()\n",
    "\n",
    "    results = {\n",
    "        \"pred\": predictions,\n",
    "        \"sum\": sums\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "img_name = \"DSC00580.JPG\"\n",
    "out_dir = \"/home/catchall/Documents/thesis/enhance/data/output/night_enhance\"\n",
    "data_dir = \"/home/catchall/Documents/thesis/enhance/data/light-effects/\"\n",
    "out_path = \"/home/catchall/Documents/thesis/enhance/data/output/night_enhance/investigate/\"\n",
    "channels = 3\n",
    "iteration = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make out_dir if not existing\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place image path in list\n",
    "images = sorted(\n",
    "    [\n",
    "        os.path.join(data_dir, img_name)\n",
    "        for file in os.listdir(data_dir)\n",
    "        if file == img_name\n",
    "    ]\n",
    ")\n",
    "image_list = images * iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageLoader = torch.utils.data.DataLoader(\n",
    "    LoadImage(image_list),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:03<00:00, 17.49it/s]\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_nc=channels, output_nc=channels)\n",
    "model = nn.DataParallel(model).cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=0.0001, betas=(0.9, 0.999)\n",
    ")\n",
    "tqdm_bar = tqdm(ImageLoader)\n",
    "results = train(model, optimizer, tqdm_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack:  0.06850504875183105\n",
      "Write:  0.03966856002807617\n",
      "Func:  0.10846304893493652\n"
     ]
    }
   ],
   "source": [
    "save_images(out_path, img_name, results, \"pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack:  0.06294822692871094\n",
      "Write:  0.03293251991271973\n",
      "Func:  0.0959775447845459\n"
     ]
    }
   ],
   "source": [
    "save_images(out_path, img_name, results, \"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
